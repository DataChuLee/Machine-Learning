---
title: "Machine Learning(메타코드M, Ch 1)"
output: html_notebook
---

### 1. 머신러닝?

-   **전문가**가 준 **데이터**를 **기계**가 **학습**하는 것

-   단어 그래도 **기계**를 **학습**한다.

-   인간이 제공한 데이터에 존재하는 관계를 표현할 수 있는 모델(= 함수)

### 2. 학습이란?

-   데이터를 가장 잘 표현할 수 있는 모델을 찾는 것(= 모델의 파라미터 최적화)

### 3. 어떻게?

-   통계적인 방법 혹은 경사하강법(딥러닝의 경우)을 이용해 최적의 파라미터를 찾는다. 머신러닝은 수학적인 방법을 더 많이 사용한다.

### 4. What is Machine Learning?

**어떤 형태의 데이터**가 머신에게 주어지는지에 따라 다음의 세부 분야들로 분류된다.

-   지도학습 : 데이터의 형태가 피쳐와 라벨이 주어진 학습 (정답지가 존재!)

-   비지도학습 : 라벨이 주어지지 않은 학습(정답지가 존재안한다!)

-   강화학습

예를 들어 야구선수의 연봉을 예측하는 모델을 만들고싶다고 하자.

머신러닝에서는 **피처**와 **라벨**이라는 것이 존재하는 데, **피쳐**는 **독립변수**이고 **라벨**은 **종속변수**이다.

-   피쳐: 데이터안에서 야구 선수의 정보 (ex. 야구선수의 경력, 타율 등)

-   라벨: 정답지이며, 즉 야구선수의 연봉이다. 우리가 모델을 통해서 예측하고 싶은 것이다.

피쳐와 같은 데이터의 정보를 이용하여 라벨(연봉)과의 관계를 통해서 머신러닝의 모델을 학습하는 것이다.

### Lecture Contents 

**Supervised Learning (지도학습)**

1.  회귀

-   Linear and Nonlinear Regression (선형과 비선형)

-   Gradient Descent (경사하강법)

-   Bias and Variance Trade-off (편향과 분산)

**Regression vs Classification**

**회귀 (Regression)**

1.  입력값: 연속값(실수형), 이산값(범주형) 등 모두 가능
2.  출력값: **연속값(실수형)**
3.   모델 형태: 일반적인 함수 상태 (Ex. y = w1x+w0 --\> 머신러닝 **모델)**

**분류(Classification)**

1.  입력값: 연속값(실수형), 이산값(범주값) 등 모두 가능
2.  출력값: **이산값(범주형)**
3.  모델 형태: 이진 분류라면 시그모이드(sigmoid)함수, 다중 분류라면 소프트맥스(softmax) 함수 꼭 포함

-   이진 분류: 이산값에서 class가 2개인 상황

-   다중 분류: 이산값에서 class가 2보다 큰 상황

### Notation (1)

**데이터의 구성**

-   데이터는 피쳐(Feature)와 라벨(Label)로 구성되어 있다.

-   이는 독립 변수와 종속 변수로도 불리우며, 라벨은 y로 표기하며 라벨의 유무로 지도학습, 비지도 학습으로 구분한다.

**Feature(= attribute, 피처)**

-   데이터 X의 **특성**, 혹은 **항목**을 의미

-   ex) 혈압, 몸무게, 나이 등

### Notation (2)

**Parameter(=weight, 파라미터, 가중치)**

-   주어진 데이터(입력값) 말고, 모델(함수)이 가지고 있는 학습 가능한 파라미터

-   ex) y = ax+b 에서 a(기울기), b(절편) 을 parameter 라고 불린다.

### Hyperparameter(하이퍼 파라미터)

-   모델 학습에 있어, 인간이 정해야하는 변수들

-   학습률, 배치 크기 등등

### **Notation(3)**

**Input(입력값) vs Output(출력값)**

-   Input: 모델(함수)에 입력되는 값으로 데이터의 **피쳐** 부분 (x로 표기)

-   Output: 모델로부터 출력되는 **예측값** (y의 \^으로 표기) / \^은 햇입니다. 추청값의 의미!

**선형 모델 vs 비선형 모델**

-   Linear regression(선형 회귀): 파라미터를 선형 결합식으로 표현 가능한 모델

    -   ex) y = w0 + w1x1 + w2x2 + ....+ wDxD / y = w0 + w1x + w2x\^2 등이 있다. 하지만 여기서 여러분들이 의구심 가질만한 식이 있다. 바로 y = w0 + w1x + w2x\^2 인데, 선형은 일차식으로 알고 있는데 왜 뜬금없이 2차인 식이 나오는 것입니까? 라고 물으시면 이유는 동일한 변수(피쳐)를 제곱한 것은 새로운 변수라고 할 수 있기 때문입니다.

-   NonLinear regression(비선형 회귀): 선형 결합식으로 표현 불가능한 모델

    -   log(y) = w0 + w1 log(x) , y = max(x,0) etc...
